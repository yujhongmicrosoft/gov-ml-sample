{"nbformat_minor": 2, "cells": [{"execution_count": 3, "cell_type": "code", "source": "from pyspark import SparkContext\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.sql.types import *\nfrom pyspark.sql import Row\nfrom pyspark.sql import SQLContext\nfrom pyspark.ml import Pipeline, PipelineModel\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.sql import functions as F\nfrom pyspark.ml.feature import HashingTF,StopWordsRemover,IDF,Tokenizer\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.mllib.regression import LabeledPoint\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.sql.functions import col, asc\nfrom pyspark.sql.types import FloatType", "outputs": [], "metadata": {"collapsed": false}}, {"source": "### Load data from Azure Storage Account", "cell_type": "markdown", "metadata": {}}, {"execution_count": 5, "cell_type": "code", "source": "texttrain = sc.textFile('wasb://ml-gov-demo@mlgovdemo.blob.core.usgovcloudapi.net/HdiSamples/HdiSamples/ml-demo/training.txt')\ntesttrain = sc.textFile('wasb://ml-gov-demo@mlgovdemo.blob.core.usgovcloudapi.net/HdiSamples/HdiSamples/ml-demo/test.txt')", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 6, "cell_type": "code", "source": "textfinal = texttrain.map(lambda (text): (float(text.split(\"\\t\")[0]), text.split(\"\\t\")[1]))\ntestfinal = testtrain.map(lambda (text): (float(text.split(\"\\t\")[0]), text.split(\"\\t\")[1]))\ntextfinallist = textfinal.collect()\ntestfinallist = testfinal.collect()\nprint textfinal.take(1)\nprint testfinal.take(1)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[(1.0, u'lynn and jon at the theaters for da vinci code-other than that, EVERYONE AT THE LUAU, it was awesome..')]\n[(1.0, u'The Da Vinci Code book is just awesome.')]"}], "metadata": {"collapsed": false}}, {"source": "### Structure Dataframe\n#### Each sentence or phrase has been labeled as 0 (negative) or 1 (positive) sentiment", "cell_type": "markdown", "metadata": {}}, {"execution_count": 7, "cell_type": "code", "source": "schema = StructType([StructField(\"label\", StringType()), \n                     StructField(\"text\", StringType())])\n\nstructuredtext = texttrain.map(lambda (textstring): (textstring.split(\"\\t\")[0],textstring.split(\"\\t\")[1:]))\nstructuredtest = testtrain.map(lambda (textstring): (textstring.split(\"\\t\")[0],textstring.split(\"\\t\")[1:]))\ndf = sqlContext.createDataFrame(structuredtext, schema)\ndftest = sqlContext.createDataFrame(structuredtest, schema)\ndf.registerTempTable(\"datatable\")\ndftest.registerTempTable(\"testtable\")\ndf.show(5)\ndftest.show(5)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+-----+--------------------+\n|label|                text|\n+-----+--------------------+\n|    1|[lynn and jon at ...|\n|    1|[The Da Vinci Cod...|\n|    1|[also, the da vin...|\n|    1|[* gasp * I LOVE ...|\n|    1|[As for movies, T...|\n+-----+--------------------+\nonly showing top 5 rows\n\n+-----+--------------------+\n|label|                text|\n+-----+--------------------+\n|    1|[The Da Vinci Cod...|\n|    1|[this was the fir...|\n|    1|[i liked the Da V...|\n|    1|[i liked the Da V...|\n|    1|[I liked the Da V...|\n+-----+--------------------+\nonly showing top 5 rows"}], "metadata": {"collapsed": false}}, {"execution_count": 8, "cell_type": "code", "source": "zeroes = df.where(col(\"label\") == \"0\")\nones = df.where(col(\"label\") == \"1\")\nprint \"Number of negatives:\" + str(zeroes.count())\nprint \"Number of positives:\" + str(ones.count())", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Number of negatives:2939\nNumber of positives:3845"}], "metadata": {"collapsed": false}}, {"execution_count": 9, "cell_type": "code", "source": "finaldf = df.select(df.label.cast('double'), df.text)\nfinaldftest = dftest.select(dftest.label.cast('double'),dftest.text)\nfinaldf.take(1)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[Row(label=1.0, text=u'[lynn and jon at the theaters for da vinci code-other than that, EVERYONE AT THE LUAU, it was awesome..]')]"}], "metadata": {"collapsed": false}}, {"source": "### TF - IDF Feature Extraction\n#### Applying weighting factor that indicates how important a word is to data", "cell_type": "markdown", "metadata": {}}, {"execution_count": 62, "cell_type": "code", "source": "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\ntokentext = tokenizer.transform(combined_df)\ntokentest = tokenizer.transform(combinedtest_df)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 63, "cell_type": "code", "source": "print tokentext.first()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Row(label=1.0, text=u'[lynn and jon at the theaters for da vinci code-other than that, EVERYONE AT THE LUAU, it was awesome..]', words=[u'[lynn', u'and', u'jon', u'at', u'the', u'theaters', u'for', u'da', u'vinci', u'code-other', u'than', u'that,', u'everyone', u'at', u'the', u'luau,', u'it', u'was', u'awesome..]'])"}], "metadata": {"collapsed": false}}, {"execution_count": 64, "cell_type": "code", "source": "newhashingTF = HashingTF(inputCol=\"words\", outputCol=\"features\", numFeatures=2000)\nhashtext = newhashingTF.transform(tokentext)\nhashtest = newhashingTF.transform(tokentest)\nprint hashtext.first()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Row(label=1.0, text=u'[lynn and jon at the theaters for da vinci code-other than that, EVERYONE AT THE LUAU, it was awesome..]', words=[u'[lynn', u'and', u'jon', u'at', u'the', u'theaters', u'for', u'da', u'vinci', u'code-other', u'than', u'that,', u'everyone', u'at', u'the', u'luau,', u'it', u'was', u'awesome..]'], features=SparseVector(2000, {333: 1.0, 417: 1.0, 436: 1.0, 495: 1.0, 745: 1.0, 756: 2.0, 893: 1.0, 1036: 1.0, 1055: 1.0, 1124: 1.0, 1234: 1.0, 1261: 1.0, 1598: 1.0, 1710: 2.0, 1793: 1.0, 1891: 1.0, 1998: 1.0}))"}], "metadata": {"collapsed": false}}, {"execution_count": 65, "cell_type": "code", "source": "idf = IDF(inputCol=\"features\").fit(hashtext)\ntfidf = idf.transform(hashtest)\nprint tfidf.first()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Row(label=1.0, text=u'[The Da Vinci Code book is just awesome.]', words=[u'[the', u'da', u'vinci', u'code', u'book', u'is', u'just', u'awesome.]'], features=SparseVector(2000, {307: 1.0, 393: 1.0, 420: 1.0, 524: 1.0, 1281: 1.0, 1521: 1.0, 1793: 1.0, 1998: 1.0}), IDF_4ff699181516231e2af0__output=SparseVector(2000, {307: 1.5145, 393: 1.4861, 420: 3.8031, 524: 2.1383, 1281: 0.4251, 1521: 4.6657, 1793: 4.62, 1998: 3.2739}))"}], "metadata": {"collapsed": false}}, {"source": "### Machine Learning Pipeline \n#### Tokenizer -> Remove unnecessary words -> TFIDF -> Naive Bayes ML model", "cell_type": "markdown", "metadata": {}}, {"execution_count": 10, "cell_type": "code", "source": "from pyspark.ml.classification import NaiveBayes\nnb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n\ntokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\nstopremover= StopWordsRemover().setInputCol(\"words\").setOutputCol(\"removed\").setCaseSensitive(False)\nnewhashingTF = HashingTF(inputCol=\"removed\", outputCol=\"features\", numFeatures=2000)\nnb_pipeline = Pipeline(stages=[tokenizer, stopremover, newhashingTF, nb])", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 11, "cell_type": "code", "source": "nb_model = nb_pipeline.fit(finaldf)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 12, "cell_type": "code", "source": "nb_predictions = nb_model.transform(finaldftest)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 13, "cell_type": "code", "source": "nb_filterdf = nb_predictions.filter( (nb_predictions.prediction==nb_predictions.label))\nprint \"Accuracy = \" + str(float(nb_filterdf.count())/float(nb_predictions.count()))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Accuracy = 0.885191347754"}], "metadata": {"collapsed": false}}, {"execution_count": 15, "cell_type": "code", "source": "nb_model.save('wasb:///HdiSamples/HdiSamples/sentimentone')", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 16, "cell_type": "code", "source": "nbmodel = PipelineModel.load('wasb:///HdiSamples/HdiSamples/sentimentone')", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 17, "cell_type": "code", "source": "testinginput = [('I hate her, she is so mean'),('This book is interesting')]\ntestrdd = sc.parallelize(testinginput)\ntemp = testrdd.map(lambda x: Row(text = x))\ntempdf = sqlContext.createDataFrame(temp)\ntestpred =nbmodel.transform(tempdf)\nprint testpred.take(2)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[Row(text=u'I hate her, she is so mean', words=[u'i', u'hate', u'her,', u'she', u'is', u'so', u'mean'], removed=[u'hate', u'her,', u'mean'], features=SparseVector(2000, {69: 1.0, 493: 1.0, 909: 1.0}), rawPrediction=DenseVector([-20.0025, -23.9995]), probability=DenseVector([0.982, 0.018]), prediction=0.0), Row(text=u'This book is interesting', words=[u'this', u'book', u'is', u'interesting'], removed=[u'book', u'interesting'], features=SparseVector(2000, {393: 1.0, 765: 1.0}), rawPrediction=DenseVector([-18.8335, -14.1577]), probability=DenseVector([0.0092, 0.9908]), prediction=1.0)]"}], "metadata": {"collapsed": false}}, {"source": "### Training on Amazon review data ", "cell_type": "markdown", "metadata": {}}, {"execution_count": 18, "cell_type": "code", "source": "amazontext = sc.textFile('wasb://ml-gov-demo@mlgovdemo.blob.core.usgovcloudapi.net/HdiSamples/HdiSamples/ml-demo/amazonreviewdata.txt')", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 19, "cell_type": "code", "source": "print amazontext.take(1)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[u'__label__2 Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^']"}], "metadata": {"collapsed": false}}, {"execution_count": 20, "cell_type": "code", "source": "testline = amazontext.first()", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 21, "cell_type": "code", "source": "testlist = testline.split(\"__label__\")\ntestlabel = testlist[1][0]\ntesttext = testlist[1][2:]\nprint testlabel\nprint testtext", "outputs": [{"output_type": "stream", "name": "stdout", "text": "2\nStuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^"}], "metadata": {"collapsed": false}}, {"execution_count": 22, "cell_type": "code", "source": "schema2 = StructType([StructField(\"label\", StringType()), \n                     StructField(\"text\", StringType())])\n\nstructuredamazontext = amazontext.map(lambda (textstring): (textstring.split(\"__label__\")[1][0],textstring.split(\"__label__\")[1][2:]))\namazondf = sqlContext.createDataFrame(structuredamazontext, schema2)\namazondf.registerTempTable(\"amazondatatable\")\namazondf.show(5)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+-----+--------------------+\n|label|                text|\n+-----+--------------------+\n|    2|Stuning even for ...|\n|    2|The best soundtra...|\n|    2|Amazing!: This so...|\n|    2|Excellent Soundtr...|\n|    2|Remember, Pull Yo...|\n+-----+--------------------+\nonly showing top 5 rows"}], "metadata": {"collapsed": false}}, {"source": "### Change Labels to 0s and 1s", "cell_type": "markdown", "metadata": {}}, {"execution_count": 23, "cell_type": "code", "source": "from pyspark.sql import functions as F\n\namazondf = amazondf.withColumn('label',\n    F.when(amazondf['label']== '1','0').when(amazondf['label']=='2','1').\n    otherwise(amazondf['label']))", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 24, "cell_type": "code", "source": "zeroes = amazondf.where(col(\"label\") == \"0\")\nones = amazondf.where(col(\"label\") == \"1\")\nprint \"Number of negatives:\" + str(zeroes.count())\nprint \"Number of positives:\" + str(ones.count())", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Number of negatives:1800000\nNumber of positives:1800000"}], "metadata": {"collapsed": false}}, {"execution_count": 25, "cell_type": "code", "source": "amazondf = amazondf.select(amazondf.label.cast('double'), amazondf.text)\nprint amazondf.take(1)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[Row(label=1.0, text=u'Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^')]"}], "metadata": {"collapsed": false}}, {"execution_count": 26, "cell_type": "code", "source": "train_amazonset, test_amazonset = amazondf.randomSplit([0.9, 0.1], 12345)", "outputs": [], "metadata": {"collapsed": true}}, {"source": "### Training model with Naive Bayes", "cell_type": "markdown", "metadata": {}}, {"execution_count": 27, "cell_type": "code", "source": "amazon_nb_model = nb_pipeline.fit(train_amazonset)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 28, "cell_type": "code", "source": "amazon_testpredictions = amazon_nb_model.transform(test_amazonset)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 29, "cell_type": "code", "source": "amazon_testpredictions.take(1)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[Row(label=0.0, text=u\"! WARNING ... WARNING ... WARNING ! read fine print: Warning, the game you are thinking about buying is NOT a game. At least is should'nt be. I have never seen such butchering of baseball or video games. I have been playing games for 20 years now and have never seen a peice of junk like this. I have played better on the SNES! Well here is the review...-PROS-N/A-CONS-* No season mode* Bad players are good, good players are bad* Will not remind you of America's favorite pasttime* Everybody looks the same* BAD gameplay* When a pitching change is made, for example, a righty stays a righty even if you bring in a lefty.* You have to swing way before you can tell what the pitch is* It has Derek Jeter on the coverSo to sum it all up, DON'T BUY THIS GAME!!!if you do, buy two of them. one to s*it on and one to cover it up with.\", words=[u'!', u'warning', u'...', u'warning', u'...', u'warning', u'!', u'read', u'fine', u'print:', u'warning,', u'the', u'game', u'you', u'are', u'thinking', u'about', u'buying', u'is', u'not', u'a', u'game.', u'at', u'least', u'is', u\"should'nt\", u'be.', u'i', u'have', u'never', u'seen', u'such', u'butchering', u'of', u'baseball', u'or', u'video', u'games.', u'i', u'have', u'been', u'playing', u'games', u'for', u'20', u'years', u'now', u'and', u'have', u'never', u'seen', u'a', u'peice', u'of', u'junk', u'like', u'this.', u'i', u'have', u'played', u'better', u'on', u'the', u'snes!', u'well', u'here', u'is', u'the', u'review...-pros-n/a-cons-*', u'no', u'season', u'mode*', u'bad', u'players', u'are', u'good,', u'good', u'players', u'are', u'bad*', u'will', u'not', u'remind', u'you', u'of', u\"america's\", u'favorite', u'pasttime*', u'everybody', u'looks', u'the', u'same*', u'bad', u'gameplay*', u'when', u'a', u'pitching', u'change', u'is', u'made,', u'for', u'example,', u'a', u'righty', u'stays', u'a', u'righty', u'even', u'if', u'you', u'bring', u'in', u'a', u'lefty.*', u'you', u'have', u'to', u'swing', u'way', u'before', u'you', u'can', u'tell', u'what', u'the', u'pitch', u'is*', u'it', u'has', u'derek', u'jeter', u'on', u'the', u'coverso', u'to', u'sum', u'it', u'all', u'up,', u\"don't\", u'buy', u'this', u'game!!!if', u'you', u'do,', u'buy', u'two', u'of', u'them.', u'one', u'to', u's*it', u'on', u'and', u'one', u'to', u'cover', u'it', u'up', u'with.'], removed=[u'!', u'warning', u'...', u'warning', u'...', u'warning', u'!', u'read', u'fine', u'print:', u'warning,', u'game', u'thinking', u'buying', u'game.', u'least', u\"should'nt\", u'be.', u'never', u'seen', u'butchering', u'baseball', u'video', u'games.', u'playing', u'games', u'20', u'years', u'never', u'seen', u'peice', u'junk', u'like', u'this.', u'played', u'better', u'snes!', u'well', u'review...-pros-n/a-cons-*', u'season', u'mode*', u'bad', u'players', u'good,', u'good', u'players', u'bad*', u'remind', u\"america's\", u'favorite', u'pasttime*', u'everybody', u'looks', u'same*', u'bad', u'gameplay*', u'pitching', u'change', u'made,', u'example,', u'righty', u'stays', u'righty', u'even', u'bring', u'lefty.*', u'swing', u'way', u'tell', u'pitch', u'is*', u'derek', u'jeter', u'coverso', u'sum', u'up,', u\"don't\", u'buy', u'game!!!if', u'do,', u'buy', u'two', u'them.', u'one', u's*it', u'one', u'cover', u'with.'], features=SparseVector(2000, {34: 1.0, 37: 1.0, 44: 2.0, 51: 1.0, 89: 1.0, 91: 1.0, 126: 2.0, 157: 1.0, 168: 1.0, 177: 1.0, 213: 2.0, 228: 1.0, 269: 1.0, 320: 1.0, 361: 1.0, 388: 1.0, 406: 1.0, 414: 1.0, 426: 1.0, 427: 1.0, 431: 1.0, 489: 1.0, 504: 2.0, 539: 1.0, 544: 1.0, 590: 1.0, 624: 1.0, 626: 1.0, 633: 1.0, 636: 1.0, 665: 1.0, 683: 1.0, 724: 1.0, 744: 1.0, 747: 1.0, 775: 1.0, 817: 2.0, 870: 1.0, 888: 1.0, 922: 1.0, 941: 1.0, 975: 1.0, 1038: 2.0, 1086: 3.0, 1089: 1.0, 1158: 1.0, 1159: 1.0, 1173: 1.0, 1276: 1.0, 1318: 1.0, 1330: 1.0, 1346: 1.0, 1408: 1.0, 1444: 1.0, 1447: 1.0, 1452: 1.0, 1505: 1.0, 1525: 1.0, 1526: 1.0, 1546: 3.0, 1588: 1.0, 1600: 2.0, 1608: 2.0, 1644: 1.0, 1650: 1.0, 1734: 1.0, 1746: 2.0, 1757: 1.0, 1770: 1.0, 1828: 1.0, 1850: 1.0, 1873: 1.0, 1906: 1.0, 1920: 1.0, 1998: 1.0}), rawPrediction=DenseVector([-626.5441, -629.8071]), probability=DenseVector([0.9631, 0.0369]), prediction=0.0)]"}], "metadata": {"collapsed": false}}, {"execution_count": 32, "cell_type": "code", "source": "amazon_filterdf = amazon_testpredictions.filter( (amazon_testpredictions.prediction==amazon_testpredictions.label))\nprint \"Accuracy = \" + str(float(amazon_filterdf.count())/float(amazon_testpredictions.count()))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Accuracy = 0.788299380228"}], "metadata": {"collapsed": false}}, {"source": "### Training Model with Logistic Regression ", "cell_type": "markdown", "metadata": {}}, {"execution_count": 33, "cell_type": "code", "source": "from pyspark.ml.classification import LogisticRegression\nlr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\nlr_pipeline = Pipeline(stages=[tokenizer,stopremover, newhashingTF, lr])\n\namazon_lr_model = lr_pipeline.fit(train_amazonset)", "outputs": [], "metadata": {"collapsed": true}}, {"source": "### NB Model without removing Stop Words", "cell_type": "markdown", "metadata": {}}, {"execution_count": 35, "cell_type": "code", "source": "from pyspark.sql.functions import lower, col\n\namazondf2 = amazondf.withColumn('text', lower(col('text')));\ntrain_amazonset2, test_amazonset2 = amazondf2.randomSplit([0.9, 0.1], 12345)\n\n#trying without stop remover\nnewhashingTF2 = HashingTF(inputCol=\"words\", outputCol=\"features\", numFeatures=2000)\nnb_pipeline2 = Pipeline(stages=[tokenizer, newhashingTF2, nb])\n\namazon_nb_model2 = nb_pipeline2.fit(train_amazonset2)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 36, "cell_type": "code", "source": "amazon_nbpredictions2 = amazon_nb_model2.transform(test_amazonset2)\nprednb = amazon_nbpredictions2.filter( (amazon_nbpredictions2.prediction==amazon_nbpredictions2.label))\nprint \"Accuracy = \" + str(float(prednb.count())/float(amazon_nbpredictions2.count()))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Accuracy = 0.797256885578"}], "metadata": {"collapsed": false}}, {"execution_count": 37, "cell_type": "code", "source": "amazon_nb_model2.save('wasb:///HdiSamples/HdiSamples/sentimenttwo')", "outputs": [], "metadata": {"collapsed": false}}, {"source": "### Adding Amazon data to previous model", "cell_type": "markdown", "metadata": {}}, {"execution_count": 38, "cell_type": "code", "source": "combined_df = finaldf.unionAll(train_amazonset)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 39, "cell_type": "code", "source": "combined_nb_model = nb_pipeline.fit(combined_df)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 40, "cell_type": "code", "source": "combinedtest_df = finaldftest.unionAll(test_amazonset)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 41, "cell_type": "code", "source": "finalpreds = combined_nb_model.transform(combinedtest_df)\nfilterred = finalpreds.filter((finalpreds.prediction==finalpreds.label))\nprint \"Accuracy = \" + str(float(filterred.count())/float(finalpreds.count()))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Accuracy = 0.788017013909"}], "metadata": {"collapsed": false}}, {"source": "### Save trained model back to Azure Storage", "cell_type": "markdown", "metadata": {}}, {"execution_count": 42, "cell_type": "code", "source": "combined_nb_model.save('wasb:///HdiSamples/HdiSamples/sentimentfinal')", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 43, "cell_type": "code", "source": "combined_nb_model = nb_pipeline.fit(combined_df)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "### Load trained model back into notebook", "cell_type": "markdown", "metadata": {}}, {"execution_count": 5, "cell_type": "code", "source": "combinedmodel = PipelineModel.load('wasb:///HdiSamples/HdiSamples/sentimentfinal')", "outputs": [], "metadata": {"collapsed": false}}, {"source": "#### We can now run test data on our trained model", "cell_type": "markdown", "metadata": {}}, {"execution_count": 6, "cell_type": "code", "source": "testinginput = [('I am excited and love the music.'),('I have been feeling tired and anxious')]\ntestrdd = sc.parallelize(testinginput)\ntemp = testrdd.map(lambda x: Row(text = x))\ntempdf = sqlContext.createDataFrame(temp)\ntestpred =combinedmodel.transform(tempdf)\nprint testpred.take(2)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[Row(text=u'I am excited and love the music.', words=[u'i', u'am', u'excited', u'and', u'love', u'the', u'music.'], removed=[u'excited', u'love', u'music.'], features=SparseVector(2000, {80: 1.0, 203: 1.0, 240: 1.0}), rawPrediction=DenseVector([-21.1538, -20.6054]), probability=DenseVector([0.3662, 0.6338]), prediction=1.0), Row(text=u'I have been feeling tired and anxious', words=[u'i', u'have', u'been', u'feeling', u'tired', u'and', u'anxious'], removed=[u'feeling', u'tired', u'anxious'], features=SparseVector(2000, {162: 1.0, 1110: 1.0, 1582: 1.0}), rawPrediction=DenseVector([-24.9139, -24.9936]), probability=DenseVector([0.5199, 0.4801]), prediction=0.0)]"}], "metadata": {"collapsed": false}}, {"source": "#### Test input: \"I am excited and love the music\"\n#### Result: probability=DenseVector([0.3662, 0.6338]), prediction=1.0 \n#### Probability of being negative sentiment = 0.3662\n#### Probability of being positive sentiment = 0.6338", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "testmodel = LogisticRegressionModel.load()", "outputs": [], "metadata": {"collapsed": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark", "name": "pysparkkernel", "language": ""}, "language_info": {"mimetype": "text/x-python", "pygments_lexer": "python2", "name": "pyspark", "codemirror_mode": {"version": 2, "name": "python"}}}}
